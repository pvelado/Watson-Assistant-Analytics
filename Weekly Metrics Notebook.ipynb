{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Watson Assistant Performance Metrics [Florida Department of Health ELI]\n\nThis notebook performs analytics on the log records of Watson Assistant. A variety of key business metrics are calculated and saved in CSV files. Optionally, this CSV data can be used to be embed into a Cognos Dashboard in Watson Studio. \n\nLogs can also be exported to spreadsheet.\n\n## Housekeeping\nThis section will import libraries and dependencies for this notebook. \n\n**Action Required:** \n- Update the `project_id` and `project_access_token` in order to access your data assets.\n- Upload `getAllLogs.py` and `extractConversations.py` into your project's assets. They can be found at https://github.com/cognitive-catalyst/WA-Testing-Tool/tree/master/log_analytics"}, {"metadata": {}, "cell_type": "markdown", "source": "### Insert Project Token"}, {"metadata": {}, "cell_type": "code", "source": "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='ec5e7dab-fb70-4af6-96b5-e79b44b0f945', project_access_token='p-ddf42113160f0687b303b59417f242c48a9e3d96')\npc = project.project_context", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Import Dependencies"}, {"metadata": {}, "cell_type": "code", "source": "# Import dependencies. Ensure these are loaded into your Studio assets.\nfobj = open(\"getAllLogs.py\", \"wb\")\nfobj.write(project.get_file(\"getAllLogs.py\").read()) \nfobj.close()\n\nfobj = open(\"extractConversations.py\", \"wb\")\nfobj.write(project.get_file(\"extractConversations.py\").read()) \nfobj.close()\n\nfobj = open(\"intent_heatmap.py\", \"wb\")\nfobj.write(project.get_file(\"intent_heatmap.py\").read()) \nfobj.close()", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%load_ext autoreload\n%autoreload 2\n%reload_ext autoreload", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Import Needed Modules"}, {"metadata": {}, "cell_type": "code", "source": "import warnings\nwarnings.simplefilter(\"ignore\")\n!pip install ibm-watson\nimport json\nimport calendar\nimport pandas as pd\nimport getAllLogs\nimport extractConversations\nimport string", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: ibm-watson in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (5.0.0)\nRequirement already satisfied: requests<3.0,>=2.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson) (2.24.0)\nRequirement already satisfied: websocket-client==0.48.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson) (0.48.0)\nRequirement already satisfied: ibm-cloud-sdk-core==1.7.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson) (1.7.3)\nRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson) (2.8.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm-watson) (1.25.9)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm-watson) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm-watson) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm-watson) (2020.12.5)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from websocket-client==0.48.0->ibm-watson) (1.15.0)\nRequirement already satisfied: PyJWT>=1.7.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-cloud-sdk-core==1.7.3->ibm-watson) (1.7.1)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Define Important Variables\nThis cell will house all the important variables to be used throughout the notebook."}, {"metadata": {}, "cell_type": "code", "source": "    # Define the customer name. This prefix will be used for saving CSV & JSON files.\ncustName = 'BON_weekly'\n\n    # Define the dates that analytics are to be ran between in \"yyyy-mm-dd\" format. Note: You will not be able to pull any results past 30 of the current date.\nstart_timestamp = \"2020-12-21\"\nend_timestamp = \"2020-12-27\"\n\n    # assistant_id can be found under the Settings -> API details for each assistant.\nassistant_id = \"88bbcf5b-bad3-41c5-bd47-b3b8c3fc5be4\"\n\n    # API, URL, and workspace ID are extractable from \"View API Details page\"\niam_apikey=\"s6EfQILQuGhIfaOwRfMroYKlkFmEcwrFSFvX3BJxfF-M\"\nurl=\"https://gateway.watsonplatform.net/assistant/api/\"\nworkspace_id=None # Update or set to None without quotes. If assistant_id is has a value, set this to None.\nversion=\"2018-09-20\"\n\n    # Below are important nodes that need to be identified in order to calulate metrics. These can be found in the JSON of each Watson Assistant Skill.\n\n    # \"Anything Else\" nodes for calculating coverage rate.\ngeneral_negative_feedback = \"node_7_1580251456692\"\nanything_else_node = \"node_2_1467831978407\"\nwds_search_node = \"node_5_1580945934910\"\n\n    # \"Escalation\" nodes for calculating escalation metrics\nescalation_node = \"node_3_1585767656658\"\nliveagent_node = \"node_2_1586552103721\"\noutofhours_node = \"node_1_1594224279859\"\n\n    # \"Chat Queue\" nodes for calculating chat queue metrics\nboard_chat_node = \"node_1_1586548298557\"\npub_rec_chat_node = \"node_2_1586532252878\"\nbgs_chat_node = \"node_3_1586532252878\"\nlss_chat_node = \"node_4_1586532252878\"\ncc_chat_node = \"node_5_1586532252878\"", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Retrieve logs from the Watson Assistant Instance\n\nConversation logs are retrieved from the watson assistant instance and are saved in JSON format.The option to save the raw json is available at the bottom of the cell if needed "}, {"metadata": {}, "cell_type": "code", "source": "\n    # Filter API is described at: https://cloud.ibm.com/docs/assistant?topic=assistant-filter-reference#filter-reference\nlog_filter=\"language::en,response_timestamp>=\"+ start_timestamp + \",response_timestamp<=\" + end_timestamp + \",request.context.system.assistant_id::\" + assistant_id  # If using this, uncomment and replace <<assistant_id>>\n\n    #Change the number of logs retrieved, default settings will return 100,000 logs (200 pages of 500)\npage_size_limit=500\npage_num_limit=20000\n\n    # Retrieves logs and saves them in JSON format\nrawLogsJson = getAllLogs.getLogs(iam_apikey, url, workspace_id, log_filter, page_size_limit, page_num_limit, version)\nrawLogsPath= custName + \"_logs.json\"\n\n\n    # Uncomment one of the two lines below if you want to save a copy of the created JSON.\n#getAllLogs.writeLogs(rawLogsJson, rawLogsPath) # Saves the logs locally\n#project.save_data(file_name = rawLogsPath,data = json.dumps(rawLogsJson),overwrite=True); # Saves the logs in Studio/COS\n    \n    # Print Statements\n#print('\\nSaved log data to {}'.format(rawLogsPath))", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "Fetched 1 log pages\nFetched 2 log pages\nFetched 3 log pages\nFetched 4 log pages\nFetched 5 log pages\nFetched 6 log pages\nFetched 7 log pages\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Format Logs \n\nThe logs are extracted and formated from the raw JSON data and saved into a Dataframe."}, {"metadata": {}, "cell_type": "code", "source": "    # Define the conversation correlation field name for your Watson Assistant records.\n    # Provide the field name as it appears in the log payload (default is 'response.context.conversation_id')\n    # For a single-skill assistant use 'response.context.conversation_id'\n    # For a Voice Gateway/Voice Agent assistant use 'request.context.vgwSessionID'\n    # For a multi-skill assistant you will need to provide your own key\nprimaryLogKey = \"response.context.conversation_id\"\n\n    # Name of the correlating key as it appears in the data frame columns (remove 'response.context.')\nconversationKey='conversation_id'\n\n    # Optionally provide a comma-separated list of custom fields you want to extract, in addition to the default fields\ncustomFieldNames = \"queue\"\n\n    #Formats and saves JSON data into a Pandas DataFrame\nallLogsDF = extractConversations.extractConversationData(rawLogsJson, primaryLogKey, customFieldNames)\nconversationsGroup = allLogsDF.groupby(conversationKey,as_index=False)\n\n    # Print Statements\nprint(\"Total log events:\",len(allLogsDF))\nprint(allLogsDF.columns)\nallLogsDF.head()\n", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Total log events: 3081\nIndex(['conversation_id', 'dialog_turn_counter', 'request_timestamp',\n       'response_timestamp', 'input.text', 'output.text', 'intent',\n       'intent_confidence', 'nodes_visited', 'branch_exited_reason', 'queue',\n       'entities', 'prev_nodes_visited', 'conversation_start', 'message_start',\n       'message_end', 'dialog_turn_number', 'conversation_length'],\n      dtype='object')\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "                        conversation_id  dialog_turn_counter  \\\n0  002674bd-90c3-4949-96b3-fbe68cb657f7                  1.0   \n1  002c357b-fe98-46b1-93aa-f4c13447a192                  1.0   \n2  004f5818-8b1f-4447-b9e4-6df01beae299                  1.0   \n3  0051868f-c196-4ffb-9a2c-d7e9f692d512                  1.0   \n4  0051868f-c196-4ffb-9a2c-d7e9f692d512                  2.0   \n\n                 request_timestamp               response_timestamp  \\\n0 2020-12-22 17:59:24.149000+00:00 2020-12-22 17:59:24.170000+00:00   \n1 2020-12-22 19:57:00.605000+00:00 2020-12-22 19:57:00.628000+00:00   \n2 2020-12-22 15:55:23.277000+00:00 2020-12-22 15:55:23.306000+00:00   \n3 2020-12-27 14:23:57.477000+00:00 2020-12-27 14:23:57.509000+00:00   \n4 2020-12-27 14:24:04.725000+00:00 2020-12-27 14:24:04.761000+00:00   \n\n           input.text                                        output.text  \\\n0  Start Conversation  Hello, I am ELI, a virtual assistant chatbot (...   \n1  Start Conversation  Hello, I am ELI, a virtual assistant chatbot (...   \n2  Start Conversation  Hello, I am ELI, a virtual assistant chatbot (...   \n3  Start Conversation  Hello, I am ELI, a virtual assistant chatbot (...   \n4         END_SESSION  I'm sorry, I'm not understanding. Can you reph...   \n\n                   intent  intent_confidence  \\\n0  Bot_Control_Start_Over           0.741890   \n1  Bot_Control_Start_Over           0.741890   \n2  Bot_Control_Start_Over           0.741890   \n3  Bot_Control_Start_Over           0.741890   \n4          General_Ending           0.341786   \n\n                                  nodes_visited branch_exited_reason queue  \\\n0                                    (Opening,)            completed         \n1                                    (Opening,)            completed         \n2                                    (Opening,)            completed         \n3                                    (Opening,)            completed         \n4  (node_1_1606141961460, node_2_1467831978407)            completed         \n\n  entities prev_nodes_visited               conversation_start  \\\n0                             2020-12-22 17:59:24.149000+00:00   \n1                             2020-12-22 19:57:00.605000+00:00   \n2                             2020-12-22 15:55:23.277000+00:00   \n3                             2020-12-27 14:23:57.477000+00:00   \n4                  (Opening,) 2020-12-27 14:23:57.477000+00:00   \n\n    message_start     message_end  dialog_turn_number  conversation_length  \n0        00:00:00        00:00:00                   1                    1  \n1        00:00:00        00:00:00                   1                    1  \n2        00:00:00        00:00:00                   1                    1  \n3        00:00:00        00:00:00                   1                    2  \n4 00:00:00.032000 00:00:07.248000                   2                    2  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversation_id</th>\n      <th>dialog_turn_counter</th>\n      <th>request_timestamp</th>\n      <th>response_timestamp</th>\n      <th>input.text</th>\n      <th>output.text</th>\n      <th>intent</th>\n      <th>intent_confidence</th>\n      <th>nodes_visited</th>\n      <th>branch_exited_reason</th>\n      <th>queue</th>\n      <th>entities</th>\n      <th>prev_nodes_visited</th>\n      <th>conversation_start</th>\n      <th>message_start</th>\n      <th>message_end</th>\n      <th>dialog_turn_number</th>\n      <th>conversation_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>002674bd-90c3-4949-96b3-fbe68cb657f7</td>\n      <td>1.0</td>\n      <td>2020-12-22 17:59:24.149000+00:00</td>\n      <td>2020-12-22 17:59:24.170000+00:00</td>\n      <td>Start Conversation</td>\n      <td>Hello, I am ELI, a virtual assistant chatbot (...</td>\n      <td>Bot_Control_Start_Over</td>\n      <td>0.741890</td>\n      <td>(Opening,)</td>\n      <td>completed</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>2020-12-22 17:59:24.149000+00:00</td>\n      <td>00:00:00</td>\n      <td>00:00:00</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>002c357b-fe98-46b1-93aa-f4c13447a192</td>\n      <td>1.0</td>\n      <td>2020-12-22 19:57:00.605000+00:00</td>\n      <td>2020-12-22 19:57:00.628000+00:00</td>\n      <td>Start Conversation</td>\n      <td>Hello, I am ELI, a virtual assistant chatbot (...</td>\n      <td>Bot_Control_Start_Over</td>\n      <td>0.741890</td>\n      <td>(Opening,)</td>\n      <td>completed</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>2020-12-22 19:57:00.605000+00:00</td>\n      <td>00:00:00</td>\n      <td>00:00:00</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004f5818-8b1f-4447-b9e4-6df01beae299</td>\n      <td>1.0</td>\n      <td>2020-12-22 15:55:23.277000+00:00</td>\n      <td>2020-12-22 15:55:23.306000+00:00</td>\n      <td>Start Conversation</td>\n      <td>Hello, I am ELI, a virtual assistant chatbot (...</td>\n      <td>Bot_Control_Start_Over</td>\n      <td>0.741890</td>\n      <td>(Opening,)</td>\n      <td>completed</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>2020-12-22 15:55:23.277000+00:00</td>\n      <td>00:00:00</td>\n      <td>00:00:00</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0051868f-c196-4ffb-9a2c-d7e9f692d512</td>\n      <td>1.0</td>\n      <td>2020-12-27 14:23:57.477000+00:00</td>\n      <td>2020-12-27 14:23:57.509000+00:00</td>\n      <td>Start Conversation</td>\n      <td>Hello, I am ELI, a virtual assistant chatbot (...</td>\n      <td>Bot_Control_Start_Over</td>\n      <td>0.741890</td>\n      <td>(Opening,)</td>\n      <td>completed</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>2020-12-27 14:23:57.477000+00:00</td>\n      <td>00:00:00</td>\n      <td>00:00:00</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0051868f-c196-4ffb-9a2c-d7e9f692d512</td>\n      <td>2.0</td>\n      <td>2020-12-27 14:24:04.725000+00:00</td>\n      <td>2020-12-27 14:24:04.761000+00:00</td>\n      <td>END_SESSION</td>\n      <td>I'm sorry, I'm not understanding. Can you reph...</td>\n      <td>General_Ending</td>\n      <td>0.341786</td>\n      <td>(node_1_1606141961460, node_2_1467831978407)</td>\n      <td>completed</td>\n      <td></td>\n      <td></td>\n      <td>(Opening,)</td>\n      <td>2020-12-27 14:23:57.477000+00:00</td>\n      <td>00:00:00.032000</td>\n      <td>00:00:07.248000</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Save All Log to CSV"}, {"metadata": {}, "cell_type": "code", "source": "     # Uncomment one of the two lines below if you want to save a copy of the created All Log Dataframe to a CSV.\n#allLogsDF.to_csv(custName + \"_logs.csv\",index=False)# This saves if running code locally. Comment out for Studio. \nproject.save_data(file_name = custName + \"_logs.csv\",data = allLogsDF.to_csv(index=False),overwrite=True) # This saves in COS. Comment out if running locally\n\n    # Print Statements\nprint('Saving metrics to {}'.format(custName+ \"_logs.csv\"))", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "Saving metrics to BON_weekly_logs.csv\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Key Metrics \n\nThe next few cells will calculate key metrics needed for analysis and save them to a CSV file that will be used to populate the Cognos Dashboard.<br><br>\nThese metrics include:\n- **Log Search Timeframe** The selected start and end date for the log search.\n- **Total Number of Messages** The number of individual messages presented in the log search.\n- **Total Number of Conversations** The number of individual conversations presented in the log search.\n- **Number of Covered Messages** The number of messages that watson assistant could give a curated response for.\n- **Coverage Rate** The percentage of covered messages.\n- **Number of Escalations** The number of time that a possible escalation to a live agent took place.\n- **Escalation Rate** The percentage of escalated occurrences in comparison to the overall number of messages.\n- **Number of Liveagent Transfers** The number of escalations that were sent to a live agent chat.\n- **Liveagent Transfer Rate** The percentage of live agent chat occurrences in comparison to the overall number of messages.\n- **Number of \"Out of Hours\" Transfers** The number of attempt to speak to a live agent out side of operating hours.\n- **\"Out of Hours\" Transfer Rate** The percentage of \"Out of Hours\" occurrences in comparison to the overall number of messages.\n- **Number of Abandoned Transfers** The number of time a user accepted to speak to an agent but did not select a queue to trigger a live agent chat.\n- **Abandoned Transfer Rate** The percentage of abandoned transfer occurrences in comparison to the overall number of messages."}, {"metadata": {}, "cell_type": "markdown", "source": "## Timeframe, Message, and Conversation Metrics\n- The selected timeframe is added to the key metrics.\n- The log is filtered for any empty inputs\n- The number of messages and conversations are added to the key metrics"}, {"metadata": {}, "cell_type": "code", "source": "    # This dict will contain the key metric data that will be later saved into a Pandas Dataframe.\nmetrics_dict = {}\n\n    # Save dates defined to dict.\nmetrics_dict['start_timestamp'] = [start_timestamp]\nmetrics_dict['end_timestamp'] = [end_timestamp]\n\n    # Filter out blank inputs in log events and saves them to a Pandas Dataframe.\nfilteredLogsDF = allLogsDF[allLogsDF['input.text'] != \"\"]\n\n    # These should match the count in the Watson Assistant Analytics tooling.\ntotalMessages= len(allLogsDF)\ntotalConvs = len(allLogsDF[conversationKey].unique())\n\n    # If any abandoned conversations are found this be different from the count above.\nfilteredMessages = len(filteredLogsDF)\nfilteredConvs = len(filteredLogsDF[conversationKey].unique())\n \n    # Save filterd message and conversation counts to dict.\nmetrics_dict['totalMessages'] = [filteredMessages] \nmetrics_dict['totalConvs'] = [filteredConvs] \n\n    # Print Statements\nprint(\"Total Messages/Total Conversations Saved to metrics_dict\")\nprint(\"Total messages:\", totalMessages)\nprint(\"Total conversations:\", totalConvs) \nprint(\"Abandoned conversations:\", totalConvs - filteredConvs)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Total Messages/Total Conversations Saved to metrics_dict\nTotal messages: 3081\nTotal conversations: 733\nAbandoned conversations: 0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Coverage \n- The number of covered messages and coverage rate are added to the key metrics."}, {"metadata": {}, "cell_type": "code", "source": "    # Saves node_id for anything_else and other uncovered nodes to a list.\nanything_else_nodes = [anything_else_node,wds_search_node,general_negative_feedback]\n\n    # Nested Loop finds the number all instances of uncovered messages.\nfor row in filteredLogsDF.itertuples():\n     nodes = row.nodes_visited\n     for node in nodes:\n         if node in anything_else_nodes:\n             anything_else_nodes.append(row.Index)\n            \n    # Saves uncoverd messages to a Pandas DataFrame\nuncoveredDF = filteredLogsDF[filteredLogsDF.index.isin(anything_else_nodes)]\n\n    # Finds the coverage rate and number of covered messages from the created dataframes.\ncoverageMetric = 1-len(uncoveredDF)/filteredMessages\ntotalCoveredMessages = totalMessages - len(uncoveredDF)\n\n    # Saves percentage and counts to dict.\nmetrics_dict['coverage_count'] = totalMessages - len(uncoveredDF)\nmetrics_dict['coverage_pcent'] = 1-len(uncoveredDF)/filteredMessages\n\n    # Print Statements\nprint(\"Number of Covered Messages/Coverage Percentage Saved to metrics_dict\")\nprint(\"Covered messages:\",totalCoveredMessages)\nprint(\"Coverage percentage:\",'{:.1%}'.format(coverageMetric))", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "Number of Covered Messages/Coverage Percentage Saved to metrics_dict\nCovered messages: 2786\nCoverage percentage: 90.4%\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Optional: Save Uncovered Messages\n- Saves a CSV file of uncovered messages that can be reviewed later WA training improvments."}, {"metadata": {}, "cell_type": "code", "source": "    #Reformates dataframe for CSV export\n#uncoveredDF = uncoveredDF[['input.text','output.text','intent','intent_confidence']]\n\nproject.save_data(file_name = custName + \"_uncovered_msgs.csv\",data = uncoveredDF.to_csv(index=False),overwrite=True); # This saves in COS. Comment out if running locally\n    # Uncomment one of the two lines below if you want to save a CSV copy of uncoered messages found.\n#uncoveredDF.to_csv(custName + \"_uncovered_msgs.csv\",index=False, header=['Utterance','Response','Intent','Confidence']) # This saves if running code locally. Comment out for Studio.\n#project.save_data(file_name = custName + \"_uncovered_msgs.csv\",data = uncoveredDF.to_csv(index=False,header=['Utterance','Response','Intent','Confidence']),overwrite=True); # This saves in COS. Comment out if running locally\n\n    # Print Statements\nuncoveredDF.head(10).sort_values('intent_confidence',ascending=False)\nprint('\\nSaved', len(uncoveredDF), 'messages to:', custName + \"_uncovered_msgs.csv\")", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "\nSaved 295 messages to: BON_weekly_uncovered_msgs.csv\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Escalations\n- Number of escalations and escalation rate are added to key metrics."}, {"metadata": {}, "cell_type": "code", "source": "    # Add in the node id for any nodes that are like an escalation.\nnode_visits_escalated = allLogsDF[[escalation_node in x for x in allLogsDF['nodes_visited']]]\n\n    # Calculates the number of escalations and the escalation percentage\ntotalEscalations = len(node_visits_escalated)\nescalationMetric = len(node_visits_escalated)/filteredConvs\n\n    # Saves escalation count and escalation percentage to dict\nmetrics_dict['escalation_count'] = [totalEscalations]\nmetrics_dict['escalation_pcent'] = [escalationMetric]\n\n    # Print Statements\nprint(\"Escalation Total/Escalation Percentage Saved to metrics_dict\")\nprint(\"Total Escalations:\",totalEscalations)\nprint(\"Escalation Percentage:\",'{:.1%}'.format(escalationMetric))", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "Escalation Total/Escalation Percentage Saved to metrics_dict\nTotal Escalations: 115\nEscalation Percentage: 15.7%\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Liveagent Transfers\n- Number of liveagent transfers and liveagent transfer rate are added to key metrics."}, {"metadata": {}, "cell_type": "code", "source": "    # This is the node id for transfer to live agent\nnode_visits_txfr_live_agent = allLogsDF[[liveagent_node in x for x in allLogsDF['nodes_visited']]]\n\n    # Calculates the number of liveagent transfers and the liveagent transfers percentage.\ntotalLiveagentTansfers = len(node_visits_txfr_live_agent)\nliveagentMetric = len(node_visits_txfr_live_agent)/filteredConvs\n\n    # Saves liveagent transfers count and liveagent transfers percentage to dict.\nmetrics_dict['liveagent_count'] = [totalLiveagentTansfers]\nmetrics_dict['liveagent_pcent'] = [liveagentMetric]\n\n    # Print Statements\nprint(\"Total Liveagent Transfers/Liveagent Transfer Percentage Saved to metrics_dict\")\nprint(\"Total Liveagent Transfers:\",totalLiveagentTansfers)\nprint(\"Liveagent Transfer Percentage\",'{:.1%}'.format(liveagentMetric))", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "Total Liveagent Transfers/Liveagent Transfer Percentage Saved to metrics_dict\nTotal Liveagent Transfers: 73\nLiveagent Transfer Percentage 10.0%\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## \"Out of Hours\" Transfers\n- Number of \"Out of Hours\" Transfers and \"Out of Hour\" Transfer Rate are added to key metrics."}, {"metadata": {}, "cell_type": "code", "source": "    # This is the node id for transfer to live agent Out of Hours\nnode_visits_outofhours = allLogsDF[[outofhours_node in x for x in allLogsDF['nodes_visited']]]\n\n    # Calculates the number of liveagent transfers Out of Hours and the liveagent transfers Our of hours percentage.\ntotalOutOfHours = len(node_visits_outofhours)\noutofhoursMetric = len(node_visits_outofhours)/filteredConvs\n\n    # Saves liveagent transfers Out of hours count and liveagent transfers out of hours percentage to dict.\nmetrics_dict['outofhours_count'] = [totalOutOfHours]\nmetrics_dict['outofhours_pcent'] = [outofhoursMetric]\n\n    # Print Statements\nprint(\"Total Liveagent Transfers OoH/Liveagent Transfer OoH Percentage Saved to metrics_dict\")\nprint(\"Total Out of Hours Transfers:\",totalOutOfHours)\nprint(\"Out of Hours Transfers Percentage\",'{:.1%}'.format(outofhoursMetric))", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "Total Liveagent Transfers OoH/Liveagent Transfer OoH Percentage Saved to metrics_dict\nTotal Out of Hours Transfers: 24\nOut of Hours Transfers Percentage 3.3%\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Abandoned Transfers\n- Number of Abandonded Transfers and Abandoned Transfer Rate are added to key metrics."}, {"metadata": {}, "cell_type": "code", "source": "    # Calculates the number of abandoned transfers and the abandoned transfers percentage.\ntotalAbandonedTransfers = totalEscalations - totalLiveagentTansfers - totalOutOfHours\nabandonedTransfersMetric = totalAbandonedTransfers/filteredConvs\n\n    # Saves abandoned transfers count and abandoned transfers percentage to dict.\nmetrics_dict['abandoned_count'] = [totalAbandonedTransfers]\nmetrics_dict['abandoned_pcent'] = [abandonedTransfersMetric]\n\n    # Print Statements\nprint (\"Total Abandoned Transfers/Abandoned Transfer Percentage Saved to metrics_dict\")\nprint(\"Total Abondoned Transfers:\",totalAbandonedTransfers)\nprint(\"Abondoned Transfers Percentage\",'{:.1%}'.format(abandonedTransfersMetric))", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "Total Abandoned Transfers/Abandoned Transfer Percentage Saved to metrics_dict\nTotal Abondoned Transfers: 18\nAbondoned Transfers Percentage 2.5%\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Save Key Metrics\n- Saves a CSV file of key metrics for review or in conjunction with Cognos Dashboard."}, {"metadata": {}, "cell_type": "code", "source": "    # Saves metrics collected from dict to Pandas Dataframe.\nmetricsDF = pd.DataFrame(metrics_dict)\n\n    # Uncomment one of the two lines below if you want to save a copy of the key metrics as a CSV.\n#metricsDF.to_csv(custName + \"_KeyMetrics.csv\",index=False) # This saves if running code locally. Comment out for Studio. \nproject.save_data(file_name = custName + \"_KeyMetrics.csv\",data = metricsDF.to_csv(index=False),overwrite=True); # This saves in COS. Comment out if running locally\n\n    # Print Statements\nprint('Saving key metrics to {}'.format(custName+ \"_KeyMetrics.csv\"))", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "Saving key metrics to BON_weekly_KeyMetrics.csv\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Daily Conversations and Messages Metric\n\nThe following few cells will calculate the number of conversations and messages for each day of the week and save them to a CSV file."}, {"metadata": {}, "cell_type": "markdown", "source": "## Daily Messages"}, {"metadata": {}, "cell_type": "code", "source": "    # Copies all log dataframe to new dataframe \ntime = allLogsDF.copy()\n\n    # Adds a new column that identifies the day of the week the message took place based on the timestamp\ntime['weekday'] = time['request_timestamp'].apply(lambda x: x.weekday())\n\n    # Creates a new Pandas dataframe that will hold the message count per day of the week.\nweekday_freq = pd.DataFrame( columns=[\"count\"], index=[0,1,2,3,4,5,6])\n\n    # Nested loop calculates the number of times a message falls on a curtain day of the week and adds it to weekday_freq dataframe.\nfor i in weekday_freq.index:\n     count = 0\n     for j in time.index:\n         if i == time.loc[j, 'weekday']:\n             count += 1\n     weekday_freq.loc[i, \"count\"] = count\n    \n    # Adds new column to dataframe that stamps the weekday name based on the index number.\nweekday_freq['Weekdays'] = calendar.day_name\n\n    # Print Statements\nweekday_freq", "execution_count": 17, "outputs": [{"output_type": "execute_result", "execution_count": 17, "data": {"text/plain": "  count   Weekdays\n0   743     Monday\n1   793    Tuesday\n2   776  Wednesday\n3   309   Thursday\n4    93     Friday\n5   207   Saturday\n6   160     Sunday", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>Weekdays</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>743</td>\n      <td>Monday</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>793</td>\n      <td>Tuesday</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>776</td>\n      <td>Wednesday</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>309</td>\n      <td>Thursday</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93</td>\n      <td>Friday</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>207</td>\n      <td>Saturday</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>160</td>\n      <td>Sunday</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Daily Conversations"}, {"metadata": {}, "cell_type": "code", "source": "    # Creates a new Pandas dataframe that will hold the conversation count per day of the week.\nweekday_conversations = pd.DataFrame(columns= [\"conversation_count\"], index = [0,1,2,3,4,5,6])\n\n    # Nested loop calculates the number of times a message falls on a certian day of the week and adds it to weekday_conversations dataframe.\nfor i in weekday_conversations.index:\n     id_list = []\n     for j in time.index:\n         if (i == time.loc[j,\"weekday\"]) and (time.loc[j,\"conversation_id\"] not in id_list):\n             id_list.append(time.loc[j, \"conversation_id\"])\n     weekday_conversations.loc [i, \"conversation_count\"] = (len(id_list))\n    \n    # Adds new column to dataframe that stamps the weekday name based on the index number.\nweekday_conversations['Weekdays'] = calendar.day_name\n\n    # Print Statements\nweekday_conversations", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "  conversation_count   Weekdays\n0                177     Monday\n1                191    Tuesday\n2                157  Wednesday\n3                 83   Thursday\n4                 27     Friday\n5                 50   Saturday\n6                 51     Sunday", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversation_count</th>\n      <th>Weekdays</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>177</td>\n      <td>Monday</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>191</td>\n      <td>Tuesday</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>157</td>\n      <td>Wednesday</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>83</td>\n      <td>Thursday</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>Friday</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50</td>\n      <td>Saturday</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>51</td>\n      <td>Sunday</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Merge Daily Messages/Conversations"}, {"metadata": {}, "cell_type": "code", "source": "    # Merges weekday dataframes created above.\nweekday_count = pd.DataFrame.from_dict({\"Day of Week\": [0,1,2,3,4,5,6],\n                                       \"Daily Conversations\": weekday_conversations['conversation_count'],\n                                       \"Daily Messages\": weekday_freq['count'],\n                                       \"Weekdays\": weekday_conversations['Weekdays']})\n    # Print Statements\nweekday_count", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "   Day of Week Daily Conversations Daily Messages   Weekdays\n0            0                 177            743     Monday\n1            1                 191            793    Tuesday\n2            2                 157            776  Wednesday\n3            3                  83            309   Thursday\n4            4                  27             93     Friday\n5            5                  50            207   Saturday\n6            6                  51            160     Sunday", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Day of Week</th>\n      <th>Daily Conversations</th>\n      <th>Daily Messages</th>\n      <th>Weekdays</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>177</td>\n      <td>743</td>\n      <td>Monday</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>191</td>\n      <td>793</td>\n      <td>Tuesday</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>157</td>\n      <td>776</td>\n      <td>Wednesday</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>83</td>\n      <td>309</td>\n      <td>Thursday</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>27</td>\n      <td>93</td>\n      <td>Friday</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>50</td>\n      <td>207</td>\n      <td>Saturday</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>51</td>\n      <td>160</td>\n      <td>Sunday</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Save Daily Conversations and Messages Metric\n- Saves a CSV file containing the Daily Conversations and Messages Metric."}, {"metadata": {}, "cell_type": "code", "source": "    # Uncomment one of the two lines below if you want to save a copy of the weekday conversations and messages count dataframe as a CSV.\n#weekday_count.to_csv(custName + \"_Weekday_Conversation_Messages.csv\",index=False) # This saves if running code locally. Comment out for Studio. \nproject.save_data(file_name=custName+\"_Weekday_Conversation_Messages.csv\", data=weekday_count.to_csv(index=False), overwrite=True)# This saves in COS. Comment out if running locally.\n\n    # Print Statements\nprint('Saving key metrics to {}'.format(custName+ \"_Weekday_Conversation_Messages.csv\"))", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "Saving key metrics to BON_weekly_Weekday_Conversation_Messages.csv\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Chat Queue Metric\n- The next couple of cells will count the number times each chat agent queue was triggered and saves the results in a CSV file."}, {"metadata": {}, "cell_type": "markdown", "source": "## Queue Count\n- The log is searched for each indevidual triggered queue and tallies them."}, {"metadata": {}, "cell_type": "code", "source": "    # Define the node_id for transfer to live agent nodes: node_1=Board call center, node_2=public records, node_3=background screening, node_4=licensure support, node_5=customer contact center\nqueue_nodes = [board_chat_node,pub_rec_chat_node,bgs_chat_node,lss_chat_node,cc_chat_node] \n\n    # Creats a new dataframe with queue names and counts (starting at 0).\nqueueCountDF = pd.DataFrame({'Queue Count':[0,0,0,0,0],\n                             'Webchat Queues' :['Board','Public Records', 'Background Screening', 'Licensure Support', \"Contact Center\"]})\n    # Calculates the number of times a specific queue\nfor i in filteredLogsDF.itertuples():\n     nodes = i.nodes_visited\n     for j in nodes:\n         if j in queue_nodes:\n             if j == board_chat_node:\n                 queueCountDF.loc[0,'Queue Count'] = queueCountDF.loc[0,'Queue Count'] + 1\n             elif j == pub_rec_chat_node:\n                 queueCountDF.loc[1,'Queue Count'] = queueCountDF.loc[1,'Queue Count'] + 1\n             elif j == bgs_chat_node:\n                 queueCountDF.loc[2,'Queue Count'] = queueCountDF.loc[2,'Queue Count'] + 1\n             elif j == lss_chat_node:\n                 queueCountDF.loc[3,'Queue Count'] = queueCountDF.loc[3,'Queue Count'] + 1\n             elif j == cc_chat_node:\n                 queueCountDF.loc[4,'Queue Count'] = queueCountDF.loc[4,'Queue Count'] + 1\n                \n    # Print Statements\nqueueCountDF", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "   Queue Count        Webchat Queues\n0           23                 Board\n1            0        Public Records\n2           10  Background Screening\n3           14     Licensure Support\n4           17        Contact Center", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Queue Count</th>\n      <th>Webchat Queues</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23</td>\n      <td>Board</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Public Records</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>Background Screening</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14</td>\n      <td>Licensure Support</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>Contact Center</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Save Chat Queue Metric\n- Saves a CSV file of Chat queue metric."}, {"metadata": {}, "cell_type": "code", "source": "    # Uncomment one of the two lines below if you want to save a copy of the queue count dataframe as a CSV.\n#queueCountDF.to_csv(custName + \"_QueueCount.csv\",index=False )# This saves if running code locally. Comment out for Studio.\nproject.save_data(file_name = custName + \"_QueueCount.csv\",data = queueCountDF.to_csv(index=False),overwrite=True) # This saves in COS. Comment out if running locally\n\n    # Print Statements\nprint('Saving key metrics to {}'.format(custName+ \"_QueueCount.csv\"))", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "Saving key metrics to BON_weekly_QueueCount.csv\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}